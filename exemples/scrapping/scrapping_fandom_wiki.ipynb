{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342ad7bf-2cd8-49d5-85f5-7f014f2c77b3",
   "metadata": {},
   "source": [
    "# Scrapping images on a fandom wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e1b90-23af-4c29-b063-ed0b370ee659",
   "metadata": {},
   "source": [
    "## Install missing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3eb33-c094-4d18-98c4-3ff93d0be3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b77079-bdc0-4067-b6df-5e7f7a827592",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('pip install jupyterlab beautifulsoup4 pillow --quiet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc4939-fcc8-49d4-a9c6-22efa8a7053a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce4efb-210d-44a1-8bb1-b9acb823ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea17e79-dc24-4618-a316-c7c43e049bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilots = \"https://intothebreach.fandom.com/wiki/Pilots\"\n",
    "veks = \"https://intothebreach.fandom.com/wiki/Vek\"\n",
    "mechs = \"https://intothebreach.fandom.com/wiki/Mechs\"\n",
    "pages = {'pilots': pilots, 'veks': veks, 'mechs': mechs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e115f-14d6-47f3-adcc-6aa2572923e3",
   "metadata": {},
   "source": [
    "## Doing one page first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f1a5a-6d76-477e-9c8a-cd177a2cc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilots_html = requests.get(pilots).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59696b72-d86e-4a83-a667-82499b0630ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(pilots_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96756c52-bff7-41af-a0bf-e9ad221c3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d6fb5-82a8-482c-90b5-38421e2566bd",
   "metadata": {},
   "source": [
    "### Pulling one image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616812a-9551-4977-b0ea-9f1149551254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the <img …> in the page\n",
    "images = soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8077d-6beb-4d6d-ac50-8b24ec1ac818",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = images[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93324d-d123-4d1b-8c4d-9505ff0eeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the image's url\n",
    "src = test.attrs.get('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052eaff-d893-4f46-805e-5a8c669e6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c324-48b9-4af6-9f27-b0060d52b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find \"png\"'s position in the url, to trim it after .png\n",
    "src.index('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020f73e-673f-425a-81ce-0f904133d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src[:src.index('png')+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427857aa-18d7-497b-812b-9de1999e6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download with wget. You can replace wget by curl if needed by commenting the wget version and uncommenting the lines of the curl version\n",
    "os.system(f\"wget -cq {src}\")\n",
    "\n",
    "# curl version\n",
    "#name = images[4].attrs.get(\"data-image-name\").replace(\" \", \"_\")\n",
    "#os.system(f\"curl {src} > {name} --silent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfe580-e3d3-4c01-bcf6-24628883f9ae",
   "metadata": {},
   "source": [
    "### Pullings all the images in one page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe1145-c2c4-433a-a1d2-22ba92341770",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cce646-c79b-492c-a055-c4463a2bc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    src = image.attrs.get('src') if \"png\" in image.attrs.get('scr', '') else image.attrs.get('data-src', '')\n",
    "    if src:\n",
    "        src = src[:src.index('png')+3]\n",
    "        # download with wget\n",
    "        #os.system(f\"wget -cq {src}\")\n",
    "        # alternative : download with curl \n",
    "        name = image.attrs.get('data-image-name').replace(' ', '_')\n",
    "        os.system(f\"curl {src} > {name} --silent\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02a5eb-12e3-4dfe-ad24-5e31dcdfa46f",
   "metadata": {},
   "source": [
    "## clean up - delete downloaded png files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc9bd5-3220-4514-a2b2-1fb10ce72f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir() if f.endswith('png')]\n",
    "if files:\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62609b26-d5ad-4d19-a9c4-855514b63d0d",
   "metadata": {},
   "source": [
    "### Download all the pngs in each page to subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b3462-b344-4d08-9ea6-ec3ac2b1d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66279529-b431-4a71-8e72-311e628c583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_image_download(pages):\n",
    "    \"\"\"From a dict of page_name: page_url, scan the html for img tags and download each png in a subfolder.\"\"\"\n",
    "    for dir_name, page_url in pages.items():\n",
    "        # get the html and turn it into a beautiful soup\n",
    "        html = requests.get(page_url).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # scan the soup for all <img> tags\n",
    "        images = soup.find_all('img')\n",
    "        # create subfolder\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        # iterate over the images. count will be used to print some text every 10 images\n",
    "        for count, image in enumerate(images, 1):\n",
    "            # get the src. It's in the attrs, but can be either in 'src' or 'data-src'\n",
    "            # use '' as alternative value for get because in tests don't work with None\n",
    "            src = image.attrs.get('src') if \"png\" in image.attrs.get('scr', '') else image.attrs.get('data-src', '')\n",
    "            # if the image was not a png, src is an empty string.\n",
    "            if src:\n",
    "                # trim down src after .png\n",
    "                src = src[:src.index('png')+3]\n",
    "                # download in the subfolder\n",
    "                os.system(f\"wget -cq {src} --directory-prefix={dir_name}\")\n",
    "                # alternative : download with curl uncomment 2 lines below\n",
    "                #name = image.attrs.get('data-image-name').replace(' ', '_')\n",
    "                #os.system(f\"curl {src} > {dir_name}/{name} --silent\")\n",
    "            if count % 10 == 0:\n",
    "                print(f\"Scanned {count} images. Note that some might not be proper pngs and thus not downloaded.\")\n",
    "        print(f\"Finished downloading {len(os.listdir(dir_name))} images in page {dir_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc269bc-6b39-4baa-af96-5d49d2707f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_image_download(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6973e5-8079-4a82-9c56-89408697de8b",
   "metadata": {},
   "source": [
    "## Now let's try our code on another similar wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3398c4-5417-4f4d-8112-f67b508bed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "slay_the_spire_base_url = \"https://slay-the-spire.fandom.com/wiki/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d573e-7429-4ba6-b32c-d08ae4f72b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "slay_the_spire_characters = ['Ironclad', 'Silent', 'Defect', 'Watcher']\n",
    "\n",
    "slay_the_spire_pages = {char: f'{slay_the_spire_base_url}{char}_Cards' for char in slay_the_spire_characters}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659c857-fba4-4463-a1a9-f8458f47787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slay_the_spire_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5514f-5fde-4e3b-b3ef-0d192d30fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_image_download(slay_the_spire_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0494df-c51d-4826-abff-093c02ad4fb2",
   "metadata": {},
   "source": [
    "## Final clean up, delete the subfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5854efd-74fd-4c8d-9a9b-5d8c3d0f68af",
   "metadata": {},
   "source": [
    "<div class='alert alert-danger'>\n",
    "    \n",
    "Use the cell below to delete all the subfolders containing the downloaded images, if you don't need them.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc845ee-d229-45bd-860e-2f4b53f0da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_delete = list(pages.keys()) + list(slay_the_spire_pages.keys())\n",
    "\n",
    "for folder in folders_to_delete:\n",
    "    shutil.rmtree(folder, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d83eb-0db3-4198-b460-cf5c50c2ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
