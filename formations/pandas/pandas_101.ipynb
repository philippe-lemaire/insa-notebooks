{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8322c711-36ef-4dca-91bd-cf691f2ea1cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd98247-066b-42b9-9cf5-05aadda39545",
   "metadata": {},
   "source": [
    "## Pandas, pour quel genre de données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd6f9b-6a0d-4c7a-b687-aaa293712eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b8fc8b-c9a9-4c22-8b84-1de3ae1117b2",
   "metadata": {},
   "source": [
    "Pour charger le package pandas et commencer à travailler, on l'importe.\n",
    "\n",
    "La convention dans la communauté Python est de l'importer en tant que `pd`, donc toute la documentation présume que c'est ce que vous avez fait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f2c8a-8f7e-431f-b529-cb2fc397ff24",
   "metadata": {},
   "source": [
    "### Représentation d'une table de données pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e4df2-adc9-433f-8a85-71e4736db71a",
   "metadata": {},
   "source": [
    "![](img/01_table_dataframe.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b68e2-e9eb-4847-ba5f-ffad58436637",
   "metadata": {},
   "source": [
    "Je veux stocker les données à propos des passagers du Titanic. Pour un certain nombre de passagers, je connais leurs noms (du texte), leur âge (des entiers), et leur sexe (M/F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823a98c-a8c1-4c3b-850c-b8f0e0a71b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": [\n",
    "            \"Braund, Mr. Owen Harris\",\n",
    "            \"Allen, Mr. William Henry\",\n",
    "            \"Bonnell, Miss. Elizabeth\",\n",
    "        ],\n",
    "        \"Age\": [22, 35, 58],\n",
    "        \"Sex\": [\"male\", \"male\", \"female\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbc1c5-67d5-4eb2-a4fd-7e9ee55843de",
   "metadata": {},
   "source": [
    "Pour créer un tableau de données à la main, on crée une instance de `DataFrame`. Si on lui passe un dictionnaire python contenant des listes, les clés du dictionnaire seront les noms des colonnes, et les valeurs du dictionnaire (des listes) seront le contenu des colonnes.\n",
    "\n",
    "Une `DataFrame` est une structure de données 2D qui peut stocker différents types de données (texte, entiers, réels, catégoriques, dates…) dans des colonnes. C'est similaire à un fichier tableur, une table SQL dans une base de données, ou l'objet `data.frame` du langage R.\n",
    "\n",
    "\n",
    "Dans notre table,\n",
    "- Il y a 3 colonnes, chacune avec son nom. Les noms sont respectivement `Name`, `Age` and `Sex`.\n",
    "- La colonne `Name` contient des données texte, chaque valeur est un string. La colonne `Age` contient des nombres, et la colonne `Sex` contient aussi du texte\n",
    "\n",
    "Dans un logiciel tableur, nos données aurait une représentation très similaire :milar:\n",
    "\n",
    "![](img/01_table_spreadsheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84220efd-be05-43c2-be3f-d5c88bbc49ed",
   "metadata": {},
   "source": [
    "### Chaque colonne est une instance de  `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccfb04c-6b79-4472-88e1-9ea9f2186c13",
   "metadata": {},
   "source": [
    "![](img/01_table_series.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ea7ab-5afe-49b6-a35e-7b2e80e12850",
   "metadata": {},
   "source": [
    "Je m'intéresse uniquement aux données dans la colonne `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7d65b-bdd9-4d44-88ab-e0defa96c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce4ea7-6aef-497d-b21c-00b3805e3e9d",
   "metadata": {},
   "source": [
    "Quand on sélectionne une seule colonne dans une `DataFrame`, le résultat est une `pandas.Series`. Pour sélectionner une colonne\n",
    "on utilise le nom de la colonne entre crochets `[]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291768c-d048-4877-8086-899dd3325935",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "Si vous êtes familiers des dictionnaires Python, la sélection d’une colonne unique est très similaire à la sélection d'une valeur dans un dictionnaire via sa clé.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463c164-bec2-4325-95d3-47e66ebb3ff0",
   "metadata": {},
   "source": [
    "On peut créer une Series ex-nihilo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f50a80-299e-4e49-bfb3-b8abbfb03476",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = pd.Series([22, 35, 58], name=\"Age\")\n",
    "ages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce41c7-e6a1-4c81-84c8-96bc6c1fac59",
   "metadata": {},
   "source": [
    "Une `pandas.Series` n'a pas de libellé de colonne, c'est juset une colonne d'une DataFrame. Mais elle a bien des libellés de ligne (par défaut 0, 1, 2 …)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a20e5-47d3-4a21-a324-97c103848d26",
   "metadata": {},
   "source": [
    "### Agir sur une `pandas.Series`\n",
    "Je veux connaître l’âge le plus élevé parmi les passagers.\n",
    "\n",
    "On peut le trouver en sélectionnant la colonne `\"Age\"` dans notre `DataFrame` et en appliquant la méthode `.max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26a686-83f4-40c9-95ee-1b1a5c4c1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6cdee1-568b-48be-96da-5c3552d9ee9f",
   "metadata": {},
   "source": [
    "Idem sur une simple `Series` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355d806-8208-4985-a780-5839d6fee189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b761a7-2041-4afe-b054-954d165a0753",
   "metadata": {},
   "source": [
    "Comme illustré par la méthode `.max()`, on peut faire des choses avec une `DataFrame` ou une `Series`. Pandas nous offre plein de fonctionnalités, sous la forme de méthodes à utiliser sur une `DataFrame` ou `Series`. Comme les méthodes sont des fonctions, pensez bien à ajouter les parenthèses après leur nom `()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e6eac-c2ce-42b6-90bd-3863d13726e5",
   "metadata": {},
   "source": [
    "### Je veux voir des statistiques de base sur mes données numériques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e000e-f631-4e7a-b5b5-99e9de39caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac04371-7098-49b0-a5df-48dcea9cc4a3",
   "metadata": {},
   "source": [
    "La méthode `describe()` nous donne un aperçu rapide des données numériques dans notre `DataFrame`. Comme les colonnes `Age` et `Sex` sont des données textuelles, elles sont ignorées par la méthode `describe()`.\n",
    "\n",
    "De nombreuses opérations renvoient une nouvelle `DataFrame` ou `Series`. La méthode `describe()` est un exemple d’opération qui renvoie une `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f541b-7fd4-41bb-a64f-ac166703d6e4",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "Ce n'est que le début. Comme dans un tableur, **pandas** représente les données sous la forme d'un tableau avec des colonnes et des lignes. En plus de la représentation, les manipulations de données et les calculs que vous pouvez faire dans un tableur sont également faisables avec **pandas**, et nous allons voir ça dans ce guide.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e59e5-1908-4d1f-b09b-90e96ea0d0e3",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "    \n",
    "**À retenir:**\n",
    "\n",
    "- On importe la bibliothèque pandas avec `import pandas as pd`\n",
    "- Un tableau de données est stocké dans un objet `pandas.DataFrame`\n",
    "- Chaque colonne dans une `DataFrame` est une `Series`\n",
    "- Vous pouvez réaliser des opérations en appliquant des méthodes à une`DataFrame` ou une`Series`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5efcf1-eb59-4f4c-9e4a-fbb9c7d85724",
   "metadata": {},
   "source": [
    "## Comment lire et écrire des données tabulaires\n",
    "\n",
    "![](img/02_io_readwrite.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd308f6a-345c-4b6e-b5a4-2d97e381c890",
   "metadata": {},
   "source": [
    "Je veux analyser les données des passagers du Titanic, disponibles sous la forme d'un fichier `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7010a3-63f8-46d5-8793-7982e39572bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un sous-dossier data\n",
    "!mkdir data\n",
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv > data/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f9b00-00d9-4156-82ba-dbb1502e080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement du CSV dans une DataFrame\n",
    "titanic = pd.read_csv(\"data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea689a6a-2b12-4a8a-b6ef-fc75f68a7e36",
   "metadata": {},
   "source": [
    "Pandas a une fonction `read_csv(path)` qui va lire les données dans un fichier csv et vous renvoie une `DataFrame`. Pandas peut lire la plupart des formats de fichier de données  (csv, excel, sql, json, parquet, …) nativement, chacun de ces formats a sa fonction `read_*`.\n",
    "\n",
    "Prenez le réflexe après avoir chargé un jeu de données de jeter un œil à la `DataFrame`. \n",
    "\n",
    "Appeler la `DataFrame` dans un notebook affiche les 5 premières et les 5 dernières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6ee01-4186-4547-badc-f0baa3710638",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215e67a-51ee-4f31-b4a6-1eebcc6427a7",
   "metadata": {},
   "source": [
    "Je veux voir les 8 premières lignes de la DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97e1b2-6c7b-4285-b641-b581cc4095f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a5620-10b7-4643-927c-526ff91bfb7a",
   "metadata": {},
   "source": [
    "La méthode `DataFrame.head(n)` permet de regarder les premières lignes (par défaut les 5 premières).\n",
    "\n",
    "De même, la méthode `.tail(n)` affiche les `n` dernières lignes, et `.sample(n)` tire `n` lignes au hasard.\n",
    "\n",
    "Pour vérifier comment pandas a interprété les données de chaque colonne, inspectez l'attribut `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5c3d6-24a1-465d-b51e-702b5243fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d1fd1-ac44-4cc5-906b-b67566a759ed",
   "metadata": {},
   "source": [
    "Pour chaque colonne, le type de données utilisé est affiché.\n",
    "\n",
    "Ici on a : \n",
    "- des entiers (int64), \n",
    "- des réels (float64),\n",
    "- des strings (object)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88863f84-33cf-4959-9ba4-9f3b86fc9879",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "Quand on demande `.dtypes`, il n’y a pas de parenthèses ! `dtypes` est un attribut des DataFrame et Series. Ce sont des variables internes, et non pas des fonctions, donc pas de parenthèses à ajouter à la fin. Les attributs sont des données internes, les méthodes (qui nécessitent des parenthèses) sont des fonctions, ou actions internes.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63294b69-c0a6-401b-9e66-08f0b225382a",
   "metadata": {},
   "source": [
    "Mon collègue me demande les données du Titanic, sous la forme d'un fichier tableur. Dans le doute, on va lui faire en Excel et en LibreOffice.\n",
    "\n",
    "On a juste deux petits packages à installer, `openpyxl` et `odfpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81c9e1-1e21-43c1-a065-53cc9ed59194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour les utilisateurs d'anaconda\n",
    "!conda install -c anaconda openpyxl odfpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ecfe5-98b8-4efe-8d05-eeb1a407d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour ceux qui utilisent pip directement\n",
    "!pip install openpyxl odfpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cceac3-7533-4dfa-88ad-bf50c7406f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un sous-dossier export\n",
    "!mkdir export\n",
    "\n",
    "# export avec la méthode .to_excel()\n",
    "titanic.to_excel(\n",
    "    \"export/titanic.xlsx\", sheet_name=\"passengers\", index=False\n",
    ")  # export vers excel\n",
    "\n",
    "titanic.to_excel(\n",
    "    \"export/titanic.ods\", sheet_name=\"passengers\", index=False, engine=\"odf\"\n",
    ")  # export vers un fichier LibreOffice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69186455-a96a-45e7-bfde-f2b4679adba8",
   "metadata": {},
   "source": [
    "Les fonctions `read_*` sont utilisées pour charger des données venant de fichiers vers une DataFrame, les fonctions `to_*` font l'opposé.\n",
    "\n",
    "Dans l'exemple ci-dessus, le nom de la feuille est spécifié (sinon ce serait bêtement \"Sheet1\". L'option `index=False` fait en sorte que le libellé de chaque ligne ne soit pas exporté.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bd63f-2df2-47a7-8959-60b43d51d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_excel(\"export/titanic.xlsx\", sheet_name=\"passengers\") # on recharge les données depuis le fichier excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf9b70-6c01-4161-b1b3-f8c01241dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head() # est-ce que tout est bien là ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203e13b-1178-4554-ac7a-e8ebc8646147",
   "metadata": {},
   "source": [
    "### ❓ Je veux un résumé technique de ma `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf210e2-af14-4d63-8ba9-70288441a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420a2d0-0620-4b6b-8bb5-23eb9dc919b2",
   "metadata": {},
   "source": [
    "La méthode `.info()` me donne un résumé technique de ma DataFrame, regardons ça plus en détail.\n",
    "\n",
    "- C'est bien une DataFrame.\n",
    "- Il y a 891 entrées, soit 891 lignes. Chaque ligne a un libellé (appelé l'index), avec des valeurs entre 0 et 890.\n",
    "- La table a 12 colonnes. \n",
    "- La plupart des colonnes ont une valeur dans chaque ligne (quand il y a 891 valeurs non-nulles). \n",
    "- Mais certaines colonnes ont moins de 891 valeurs non-nulles, donc il y a des valeurs manquantes par endroits. \n",
    "- Les colonnes `Name`, `Sex`, `Cabin` et `Embarked` sont des données textuelles (strings, ici désigné en tant que \"object\"). \n",
    "- Les autres colonnes sont numériques, certaines sont des entiers, d'autres des réels (float).\n",
    "- Une estimation de l’emprunte mémoire de la DataFrame est indiquée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b50cba-6d5e-4b77-8191-eaebce693319",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "**À retenir**\n",
    "    \n",
    "- Obtenir des données depuis différents types de fichiers est fait avec les fonctions qui commencent par `read_`.\n",
    "- Exporter les données depuis pandas vers un fichier est fait par les différentes méthodes de DataFrame qui commencent par `to_`.\n",
    "- Les méthodes `head`, `tail`, `info` et l'attribut `dtypes` sont utiles pour faire une première vérification sur les données .\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5483f3-9dba-42fc-bdb7-6aeca0a8f0fc",
   "metadata": {},
   "source": [
    "## Sélectionner un sous-ensemble d'une `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd3c7c-49a3-4db0-b235-4473ed1a4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la dataframe en repartant du CSV titanic\n",
    "titanic = pd.read_csv(\"data/titanic.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dfc61b-8a89-4bdc-8c9c-99683a0864e4",
   "metadata": {},
   "source": [
    "### ❓ Comment sélectionner certaines colonnes \n",
    "\n",
    "![](img/03_subset_columns.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246301c-4dfe-428d-aef3-17f1d2f1e2ca",
   "metadata": {},
   "source": [
    "Je veux uniquement l'âge des passagers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db4efc-f809-4103-b30e-8115160047c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = titanic[\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e21d89-df58-40af-ae35-ac0dcbd6cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb573e-b952-4f9a-8d41-c692cd18d2c0",
   "metadata": {},
   "source": [
    "Pour sélectionner une seul colonne, on utilise des crochets `[]` avec le nom de la colonne.\n",
    "\n",
    "Chaque colonne est un objet `Series`. Quand on sélectionne une seule colonne, l'objet renvoyé est une `Series`. On peut s'en assurer avec la \n",
    "foction `type()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1d785-27ef-47b3-862f-d17025b4a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(titanic[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aab65e-a431-4767-bbd7-80fe3400f108",
   "metadata": {},
   "source": [
    "Ou regarder la forme de cet objet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24419f25-7be5-4ad7-ab21-173576c10cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695f6464-9e32-4350-85b9-5fc12cb8f99e",
   "metadata": {},
   "source": [
    "`.shape` est un attribut (souvenez-vous, ce n'est pas une méthode, pas de parenthèses) sur une DataFrame ou une Series, qui contient le nombre de lignes et de colonnes. (nlignes, ncolonnes). \n",
    "\n",
    "Une Series est un tableau à 1 dimension, donc le tuple ne contient que le nombre de lignes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc765f7-e52d-4fae-8684-9d9870c823fb",
   "metadata": {},
   "source": [
    "---\n",
    "Je veux m'intéresser à l'âge et au sexe des passagers du Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef513ab-b1ec-446d-8f85-e35b19445ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sex = titanic[[\"Age\", \"Sex\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb384737-6762-44c3-8106-1221d9f67db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f065ad1-2d43-4947-ae86-fc2b17fd27fc",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "To select multiple columns, use a list of column names within the selection brackets [].\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "\n",
    "The inner square brackets define a Python list with column names, whereas the outer brackets are used to select the data from a pandas DataFrame as seen in the previous example.\n",
    "\n",
    "</div>\n",
    "\n",
    "The returned data type is a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18100818-8834-4063-835c-688dc1d1fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(titanic[[\"Age\", \"Sex\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aed008-55d3-4b4e-978a-f96538794975",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[[\"Age\", \"Sex\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f2ffdd-7022-449d-87bf-e61ac8227d04",
   "metadata": {},
   "source": [
    "The selection returned a DataFrame with 891 rows and 2 columns. Remember, a DataFrame is 2-dimensional with both a row and column dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81759517-29de-4c3f-9dcd-c78cf04f807d",
   "metadata": {},
   "source": [
    "### Comment sélectionner certaines lignes dans la `DataFrame` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9eb735-27d5-4ca6-8a3c-5c026ecd8de5",
   "metadata": {},
   "source": [
    "I’m interested in the passengers older than 35 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6270b-5f26-4e25-8340-5b5bd6028e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_35 = titanic[titanic[\"Age\"] > 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1d892-f5e5-4d34-862f-dc764aecbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_35.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0164e2-2744-4d6e-bc35-73f965a3ae6f",
   "metadata": {},
   "source": [
    "To select rows based on a conditional expression, use a condition inside the selection brackets []."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1113833-b6ab-4058-9fcc-31d440625581",
   "metadata": {},
   "source": [
    "The condition inside the selection brackets titanic[\"Age\"] > 35 checks for which rows the Age column has a value larger than 35:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fac6b4-cfca-479e-82ae-520093a5416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"] > 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c3e87e-e338-49ba-9aa5-eaa681cb2179",
   "metadata": {},
   "source": [
    "The output of the conditional expression (>, but also ==, !=, <, <=,… would work) is actually a pandas Series of boolean values (either True or False) with the same number of rows as the original DataFrame. Such a Series of boolean values can be used to filter the DataFrame by putting it in between the selection brackets []. Only rows for which the value is True will be selected.\n",
    "\n",
    "We know from before that the original Titanic DataFrame consists of 891 rows. Let’s have a look at the number of rows which satisfy the condition by checking the shape attribute of the resulting DataFrame above_35:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab54398-d17c-4277-a70e-f1c29a93df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_35.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca64d3-b63e-4aee-97fa-fec0185e974c",
   "metadata": {},
   "source": [
    "I’m interested in the Titanic passengers from cabin class 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f061c0-4400-4878-879b-d46e61f4cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_23 = titanic[titanic[\"Pclass\"].isin([2, 3])]\n",
    "class_23.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5f237-77da-4df0-9e8f-03561657ffb7",
   "metadata": {},
   "source": [
    "Similar to the conditional expression, the isin() conditional function returns a True for each row the values are in the provided list. To filter the rows based on such a function, use the conditional function inside the selection brackets []. In this case, the condition inside the selection brackets titanic[\"Pclass\"].isin([2, 3]) checks for which rows the Pclass column is either 2 or 3.\n",
    "\n",
    "\n",
    "The above is equivalent to filtering by rows for which the class is either 2 or 3 and combining the two statements with an | (or) operator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5be29-749f-4d74-9235-78283b696dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_23 = titanic[(titanic[\"Pclass\"] == 2) | (titanic[\"Pclass\"] == 3)]\n",
    "\n",
    "class_23.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8beee-88a2-4889-a3ac-27b332a89a9d",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "\n",
    "\n",
    "When combining multiple conditional statements, each condition must be surrounded by parentheses (). Moreover, you can not use or/and but need to use the or operator | and the and operator &.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29709490-e698-40b3-8f40-c1fa81a3a614",
   "metadata": {},
   "source": [
    "I want to work with passenger data for which the age is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb99a15b-4f6f-4d1b-9645-130083fe258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_no_na = titanic[titanic[\"Age\"].notna()]\n",
    "age_no_na.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c1469-ea9e-445b-abd2-1bdfdf20a198",
   "metadata": {},
   "source": [
    "The notna() conditional function returns a True for each row the values are not an Null value. As such, this can be combined with the selection brackets [] to filter the data table.\n",
    "\n",
    "You might wonder what actually changed, as the first 5 lines are still the same values. One way to verify is to check if the shape has changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a4e90-b6a4-42d7-a365-56b6f13d4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_no_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab5c02-91c9-4ba0-8b59-70ce21459c8f",
   "metadata": {},
   "source": [
    "### Comment sélectionner des lignes et colonnes spécifiques\n",
    "\n",
    "![](img/03_subset_columns_rows.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea1ed6-5a9d-416a-a03b-a102cc604f4d",
   "metadata": {},
   "source": [
    "I’m interested in the names of the passengers older than 35 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6d91a-feb1-4ff4-882a-a94ab7ea05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_names = titanic.loc[titanic[\"Age\"] > 35, \"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f37160-7e88-44d0-942e-23466d3b65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde67979-d326-41c1-9b0f-3ef6d98d45f0",
   "metadata": {},
   "source": [
    "In this case, a subset of both rows and columns is made in one go and just using selection brackets [] is not sufficient anymore. The loc/iloc operators are required in front of the selection brackets []. When using loc/iloc, the part before the comma is the rows you want, and the part after the comma is the columns you want to select."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d37ebcf-f95d-453b-8863-3452cbe4a38a",
   "metadata": {},
   "source": [
    "When using the column names, row labels or a condition expression, use the loc operator in front of the selection brackets []. For both the part before and after the comma, you can use a single label, a list of labels, a slice of labels, a conditional expression or a colon. Using a colon specifies you want to select all rows or columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a2ddd-a016-4ddb-856a-bab1759a486f",
   "metadata": {},
   "source": [
    "I’m interested in rows 10 till 25 and columns 3 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6377e5a-261e-489a-a5ce-a0b02b84e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.iloc[9:25, 2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c354fc-3cc1-4e19-8a6a-7e24db1a4a04",
   "metadata": {},
   "source": [
    "    Again, a subset of both rows and columns is made in one go and just using selection brackets [] is not sufficient anymore. When specifically interested in certain rows and/or columns based on their position in the table, use the iloc operator in front of the selection brackets [].\n",
    "\n",
    "When selecting specific rows and/or columns with loc or iloc, new values can be assigned to the selected data. For example, to assign the name anonymous to the first 3 elements of the third column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b655c-5f50-4cbc-904b-106c68424da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.iloc[0:3, 3] = \"anonymous\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5ed57-7a29-44e8-b72a-d6282d65ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc60f22-ec48-4103-9af5-08f79bbcb16d",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "\n",
    "REMEMBER\n",
    "\n",
    "- When selecting subsets of data, square brackets [] are used.\n",
    "\n",
    "-   Inside these brackets, you can use a single column/row label, a list of column/row labels, a slice of labels, a conditional expression or a colon.\n",
    "\n",
    "-   Select specific rows and/or columns using loc when using the row and column names\n",
    "\n",
    "-   Select specific rows and/or columns using iloc when using the positions in the table\n",
    "\n",
    "-   You can assign new values to a selection based on loc/iloc.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068a456-5e5a-422b-82a0-b1e25d0ca3dc",
   "metadata": {},
   "source": [
    "## Comment faire des graphes en Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dcce9e-a1a3-405a-aa1c-7558e62f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b58551-5ecf-4fa5-a9de-5ad0755b42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2.csv > data/air_quality_no2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519c8a6-4e2e-4a02-93b9-38ad9f86a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.read_csv(\"data/air_quality_no2.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74510b97-e3fd-45d2-a227-a74874e159d1",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "\n",
    "\n",
    "The usage of the index_col and parse_dates parameters of the read_csv function to define the first (0th) column as index of the resulting DataFrame and convert the dates in the column to Timestamp objects, respectively.\n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n",
    "![](img/04_plot_overview.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c008e7-1ce4-4272-8f54-f5b80c5b3014",
   "metadata": {},
   "source": [
    "I want a quick visual check of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560a82c-df7c-47f1-aa6d-6d741cc79ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb023f-a505-4ea2-aed1-1bad7ca0d32d",
   "metadata": {},
   "source": [
    "With a DataFrame, pandas creates by default one line plot for each of the columns with numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60108c6d-a177-4b7e-b72d-f78b5b3f5f14",
   "metadata": {},
   "source": [
    "I want to plot only the columns of the data table with the data from Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789adcb-3fb9-4877-921e-9f39bf890281",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"station_paris\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc3104-24bf-4b76-9af3-712a67579614",
   "metadata": {},
   "source": [
    "To plot a specific column, use the selection method of the subset data tutorial in combination with the plot() method. Hence, the plot() method works on both Series and DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0adf6-e724-4476-b9ef-d9bec59a13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.plot.scatter(x=\"station_london\", y=\"station_paris\", alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deaad3a-017a-4a0a-806b-d8177e686c5c",
   "metadata": {},
   "source": [
    "Apart from the default line plot when using the plot function, a number of alternatives are available to plot data. Let’s use some standard Python to get an overview of the available plot methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f54c67-f3af-4ddf-a393-87f36bec3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    method_name\n",
    "    for method_name in dir(air_quality.plot)\n",
    "    if not method_name.startswith(\"_\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aea5e3-4b14-4eb5-85b4-80ec8b4f60d3",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "In many development environments as well as IPython and Jupyter Notebook, use the TAB button to get an overview of the available methods, for example air_quality.plot. + TAB.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172aa88f-4340-4075-9dfc-229e7aff99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.plot.box();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530a986-e198-45b8-a08e-f355fbc2a8e9",
   "metadata": {},
   "source": [
    "I want each of the columns in a separate subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af2869-18c5-4710-8ff2-e06e66efe1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = air_quality.plot.area(figsize=(12, 4), subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ea3e9-b0d2-48e1-bc48-ba712e824689",
   "metadata": {},
   "source": [
    "Separate subplots for each of the data columns are supported by the subplots argument of the plot functions. The builtin options available in each of the pandas plot functions are worth reviewing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54912269-1496-430f-b018-b24dbdb3496b",
   "metadata": {},
   "source": [
    "I want to further customize, extend or save the resulting plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57883a9f-8f3b-4280-96d9-e8162b325f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 4))\n",
    "air_quality.plot.area(ax=axs)\n",
    "axs.set_ylabel(\"NO$_2$ concentration\")\n",
    "fig.savefig(\"export/no2_concentrations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb9e4a-9bb9-4cd4-a7cf-cf9242ea3b3f",
   "metadata": {},
   "source": [
    "Each of the plot objects created by pandas is a matplotlib object. As Matplotlib provides plenty of options to customize plots, making the link between pandas and Matplotlib explicit enables all the power of matplotlib to the plot. This strategy is applied in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe012046-f3ea-491c-b066-e5f4de898026",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 4))  # Create an empty matplotlib Figure and Axes\n",
    "air_quality.plot.area(\n",
    "    ax=axs\n",
    ")  # Use pandas to put the area plot on the prepared Figure/Axes\n",
    "axs.set_ylabel(\"NO$_2$ concentration\")  # Do any matplotlib customization you like\n",
    "fig.savefig(\n",
    "    \"export/no2_concentrations.png\"\n",
    ")  # Save the Figure/Axes using the existing matplotlib method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e4f8b-c86a-4aaf-a13c-19237f1f4140",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "- The `.plot.*` methods are applicable on both Series and DataFrames\n",
    "- By default, each of the columns is plotted as a different element (line, boxplot,…)\n",
    "- Any plot created by pandas is a Matplotlib object.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686de001-13f2-4cba-bba7-7cdcbf4b36e5",
   "metadata": {},
   "source": [
    "## Comment créer de nouvelles colonnes dérivées des colonnes existantes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0580a7-a8f7-49cf-8cd1-0ac5ca41f094",
   "metadata": {},
   "source": [
    "![](img/05_newcolumn_1.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337bf00-d70d-4f5d-b97b-da95ee41d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.read_csv(\"data/air_quality_no2.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52196f6-ead7-427c-a981-89be44f6a0a7",
   "metadata": {},
   "source": [
    "I want to express the $NO_2$ concentration of the station in London in mg/m\n",
    "\n",
    "*(If we assume temperature of 25 degrees Celsius and pressure of 1013 hPa, the conversion factor is 1.882)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87713e7e-6547-469a-8dbb-908255faaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"london_mg_per_cubic\"] = air_quality[\"station_london\"] * 1.882\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1b82c-0f6c-4f27-9b25-28fe89529e05",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "The calculation of the values is done element_wise. This means all values in the given column are multiplied by the value 1.882 at once. You do not need to use a loop to iterate each of the rows!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f3cfc-4deb-400b-b57c-d350a030a2e7",
   "metadata": {},
   "source": [
    "![](img/05_newcolumn_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17cda81-a0cb-47d4-b7c4-eee53b2d4e47",
   "metadata": {},
   "source": [
    "I want to check the ratio of the values in Paris versus Antwerp and save the result in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44803528-186a-4cec-a5db-4d7c47daf5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"ratio_paris_antwerp\"] = (\n",
    "    air_quality[\"station_paris\"] / air_quality[\"station_antwerp\"]\n",
    ")\n",
    "\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b203cf3-1841-41e1-8338-df38a53d5095",
   "metadata": {},
   "source": [
    "    The calculation is again element-wise, so the / is applied for the values in each row.\n",
    "\n",
    "Also other mathematical operators (+, -, \\*, /) or logical operators (<, >, =,…) work element wise. The latter was already used in the subset data tutorial to filter rows of a table using a conditional expression.\n",
    "\n",
    "If you need more advanced logic, you can use arbitrary Python code via apply().\n",
    "\n",
    "    I want to rename the data columns to the corresponding station identifiers used by openAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4b293-0b8d-4aaf-88df-3d54cadf4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_renamed = air_quality.rename(\n",
    "    columns={\n",
    "        \"station_antwerp\": \"BETR801\",\n",
    "        \"station_paris\": \"FR04014\",\n",
    "        \"station_london\": \"London Westminster\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33727844-9cc8-454b-b1dc-adee98c741f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752922e4-fb2f-469b-9880-88c331491206",
   "metadata": {},
   "source": [
    "    The rename() function can be used for both row labels and column labels. Provide a dictionary with the keys the current names and the values the new names to update the corresponding names.\n",
    "\n",
    "The mapping should not be restricted to fixed names only, but can be a mapping function as well. For example, converting the column names to lowercase letters can be done using a function as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43f97d-031a-4f03-8c31-cee8c6e68309",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_renamed = air_quality_renamed.rename(columns=str.lower)\n",
    "\n",
    "air_quality_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9aa78c-e153-4ab7-a733-0b8ba1d09f50",
   "metadata": {},
   "source": [
    "<div class'alert alert-info'>\n",
    "\n",
    "\n",
    "- Create a new column by assigning the output to the DataFrame with a new column name in between the [].\n",
    "- Operations are element-wise, no need to loop over rows.\n",
    "- Use rename with a dictionary or function to rename row labels or column names.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e78325-5bb0-4363-8f0c-ac023dbad96b",
   "metadata": {},
   "source": [
    "## Comment calculer des statistiques sur mes données \n",
    "Données pour cette section : Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47d17a-35eb-47f6-b95d-2c58e59c3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recréons notre DataFrame titanic à partir du csv\n",
    "titanic = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bb0b5-360d-4255-94f0-621685fe639e",
   "metadata": {},
   "source": [
    "### stats aggrégées\n",
    "\n",
    "![](img/06_aggregate.svg)\n",
    "\n",
    "What is the average age of the Titanic passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc88334-50db-4a5f-a653-c6a2430da816",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab75f2-cfd8-4845-98a6-db9804ba30b6",
   "metadata": {},
   "source": [
    "Different statistics are available and can be applied to columns with numerical data. Operations in general exclude missing data and operate across rows by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e9a9c-09ac-480b-bbe3-d28f8b4939a9",
   "metadata": {},
   "source": [
    "![](img/06_reduction.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d0111-dad9-4cb9-a7e5-7c71d5f12922",
   "metadata": {},
   "source": [
    "What is the median age and ticket fare price of the Titanic passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d74570-fa2f-45ea-9d54-45557d3b5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[[\"Age\", \"Fare\"]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1481bc8-e848-4ebf-97b6-6e749f0e0bd9",
   "metadata": {},
   "source": [
    "    The statistic applied to multiple columns of a DataFrame (the selection of two columns return a DataFrame, see the subset data tutorial) is calculated for each numeric column.\n",
    "\n",
    "The aggregating statistic can be calculated for multiple columns at the same time. Remember the describe function from first tutorial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef1970-365b-4e2b-b783-4223c2c3c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[[\"Age\", \"Fare\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758ed1a-4597-4efa-b73f-f72301eb9f9a",
   "metadata": {},
   "source": [
    "Instead of the predefined statistics, specific combinations of aggregating statistics for given columns can be defined using the DataFrame.agg() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb2f94-6c7e-4e42-9a71-3f24af9ef353",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.agg(\n",
    "    {\n",
    "        \"Age\": [\"min\", \"max\", \"median\", \"skew\"],\n",
    "        \"Fare\": [\"min\", \"max\", \"median\", \"mean\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129b9bf-1bb2-4938-8ad0-6d2df6bcfa41",
   "metadata": {},
   "source": [
    "## Aggregating statistics grouped by category\n",
    "\n",
    "![](img/06_groupby.svg)\n",
    "\n",
    "What is the average age for male versus female Titanic passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b7775-d84c-4a4d-a9a1-820495d0dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[[\"Sex\", \"Age\"]].groupby(\"Sex\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508cc6aa-4a32-4238-9fbe-4ad612ef065a",
   "metadata": {},
   "source": [
    "As our interest is the average age for each gender, a subselection on these two columns is made first: titanic[[\"Sex\", \"Age\"]]. Next, the groupby() method is applied on the Sex column to make a group per category. The average age for each gender is calculated and returned.\n",
    "\n",
    "https://pandas.pydata.org/docs/_images/06_groupby.svg\n",
    "\n",
    "Calculating a given statistic (e.g. mean age) for each category in a column (e.g. male/female in the Sex column) is a common pattern. The groupby method is used to support this type of operations. More general, this fits in the more general split-apply-combine pattern:\n",
    "\n",
    "- Split the data into groups\n",
    "- Apply a function to each group independently\n",
    "- Combine the results into a data structure\n",
    "\n",
    "The apply and combine steps are typically done together in pandas.\n",
    "\n",
    "In the previous example, we explicitly selected the 2 columns first. If not, the mean method is applied to each column containing numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f516028-d1e2-448b-8aa5-5cfa19094f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(\"Sex\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fd981-48fe-4dd5-8be7-d46dcef7b838",
   "metadata": {},
   "source": [
    "It does not make much sense to get the average value of the Pclass. if we are only interested in the average age for each gender, the selection of columns (rectangular brackets [] as usual) is supported on the grouped data as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e220c6a-cf82-424c-8fd8-47af02b41428",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(\"Sex\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a2ba0-6c4a-4482-95f2-bef3fcb06813",
   "metadata": {},
   "source": [
    "![](06_groupby_select_detail.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858b8a5-218a-4ecd-9e4f-5d44b1da6a88",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "The Pclass column contains numerical data but actually represents 3 categories (or factors) with respectively the labels ‘1’, ‘2’ and ‘3’. Calculating statistics on these does not make much sense. Therefore, pandas provides a Categorical data type to handle this type of data. More information is provided in the user guide Categorical data section.\n",
    "\n",
    "</div>\n",
    "\n",
    "What is the mean ticket fare price for each of the sex and cabin class combinations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32783f9b-6002-404c-990d-add92ba8adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby([\"Sex\", \"Pclass\"])[\"Fare\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807999c-72e5-4281-92d8-f450dbf90415",
   "metadata": {},
   "source": [
    "Grouping can be done by multiple columns at the same time. Provide the column names as a list to the groupby() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d8a75-ed95-42e0-84dc-4850102e210b",
   "metadata": {},
   "source": [
    "### Compter le nombre d’enregistrements par catégorie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2f5f3-b5a8-4d50-9654-4c2b943d5073",
   "metadata": {},
   "source": [
    "![](img/06_valuecounts.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7680ab-d385-416d-a016-4590222c5cec",
   "metadata": {},
   "source": [
    "    The value_counts() method counts the number of records for each category in a column.\n",
    "\n",
    "The function is a shortcut, as it is actually a groupby operation in combination with counting of the number of records within each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f74e3c-3240-47b7-9603-a50b88c1ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(\"Pclass\")[\"Pclass\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c935e1f-f584-423d-aa9d-478d37db6bcb",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "\n",
    "Both size and count can be used in combination with groupby. Whereas size includes NaN values and just provides the number of rows (size of the table), count excludes the missing values. In the value_counts method, use the dropna argument to include or exclude the NaN values.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e21a1-4cb5-415a-9a8a-e87739108c8d",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "\n",
    "\n",
    "- Aggregation statistics can be calculated on entire columns or rows\n",
    "- groupby provides the power of the split-apply-combine pattern\n",
    "- value_counts is a convenient shortcut to count the number of entries in each category of a variable\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3d8a8-aa79-4bcd-8b16-793c366f2713",
   "metadata": {},
   "source": [
    "## How to reshape the layout of tables\n",
    "\n",
    "### Données pour cette section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56eede-330c-45a7-aaad-0709f4bec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e356011-1885-4801-84aa-4dccce5a5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_long.csv > data/air_quality_long.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76823c74-190e-4803-9748-bd14192df773",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.read_csv(\n",
    "    \"data/air_quality_long.csv\", index_col=\"date.utc\", parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e760a8-f669-4c3f-9d98-f68572bcf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbbd92-6990-4b81-85ec-258563e121a5",
   "metadata": {},
   "source": [
    "### Classer les lignes de la `DataFrame`\n",
    "\n",
    "I want to sort the Titanic data according to the age of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097dbb26-8948-445b-b61e-bc6b6192a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sort_values(by=\"Age\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706b440-103b-418f-87e0-4d0d2ab3b499",
   "metadata": {},
   "source": [
    "I want to sort the Titanic data according to the cabin class and age in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be69af-f4b4-40ce-9649-d2be318aa22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sort_values(by=[\"Pclass\", \"Age\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39883e68-9e01-4764-97e9-f02c6613e4af",
   "metadata": {},
   "source": [
    "With `Series.sort_values()`, the rows in the table are sorted according to the defined column(s). The index will follow the row order.\n",
    "\n",
    "\n",
    "### Long to wide table format\n",
    "\n",
    "\n",
    "Let’s use a small subset of the air quality data set. We focus on data and only use the first two measurements of each location (i.e. the head of each group). The subset of data will be called no2_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2602611-ad5b-4c4d-bf0c-170d2e7f5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for no2 data only\n",
    "\n",
    "no2 = air_quality[air_quality[\"parameter\"] == \"no2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e8fcd-605b-41dc-8e09-035a5be63a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 2 measurements (head) for each location (groupby)\n",
    "\n",
    "no2_subset = no2.sort_index().groupby([\"location\"]).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414fcff-78e4-4cde-90a9-ac9c98aa085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71a453-b0f6-4814-86fe-8f9719ae0113",
   "metadata": {},
   "source": [
    "![](img/07_pivot.svg)\n",
    "\n",
    "I want the values for the three stations as separate columns next to each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8f240-23e8-4be1-86d4-c6d264448028",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_subset.pivot(columns=\"location\", values=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77653cda-3698-4965-818c-2c38aea2af21",
   "metadata": {},
   "source": [
    "The `pivot()` function is purely reshaping of the data: a single value for each index/column combination is required.\n",
    "\n",
    "As pandas support plotting of multiple columns (see plotting tutorial) out of the box, the conversion from long to wide table format enables the plotting of the different time series at the same time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1070ff-cb18-4f28-8714-74bb0c6b1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b2055-36f2-4111-895a-63c31a123635",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.pivot(columns=\"location\", values=\"value\").plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2c087-0cff-45d7-9e50-412c65b7b1dd",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "When the index parameter is not defined, the existing index (row labels) is used.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de03f31-2473-489e-8f96-cb24fa05947f",
   "metadata": {},
   "source": [
    "### Pivoter la table\n",
    "\n",
    "![](img/07_pivot_table.svg)\n",
    "\n",
    "\n",
    "I want the mean concentrations for $NO_2$ and $PM_{2.5}$ in each of the stations in table form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d941e-af72-4c1a-9f8f-cee92abaff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.pivot_table(\n",
    "    values=\"value\", index=\"location\", columns=\"parameter\", aggfunc=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ddefc-e213-4c44-b070-d6ab9c2e2906",
   "metadata": {},
   "source": [
    "In the case of pivot(), the data is only rearranged. When multiple values need to be aggregated (in this specific case, the values on different time steps) pivot_table() can be used, providing an aggregation function (e.g. mean) on how to combine these values.\n",
    "\n",
    "Pivot table is a well known concept in spreadsheet software. When interested in summary columns for each variable separately as well, put the margin parameter to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a38928-a8cc-4e68-8c11-1534223efb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.pivot_table(\n",
    "    values=\"value\",\n",
    "    index=\"location\",\n",
    "    columns=\"parameter\",\n",
    "    aggfunc=\"mean\",\n",
    "    margins=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab4ab3-b908-4a48-9bdf-407a06ff16ab",
   "metadata": {},
   "source": [
    "In case you are wondering, pivot_table() is indeed directly linked to groupby(). The same result can be derived by grouping on both parameter and location:\n",
    "\n",
    "`air_quality.groupby([\"parameter\", \"location\"]).mean()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee930569-a10c-490c-a03f-996a7e681999",
   "metadata": {},
   "source": [
    "### Wide to long format\n",
    "\n",
    "Starting again from the wide format table created in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0af2d4-9e2f-4e34-8a66-e55cf52bf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_pivoted = no2.pivot(columns=\"location\", values=\"value\").reset_index()\n",
    "\n",
    "no2_pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836a1d9-b426-4ae1-bccb-2a990b87d21d",
   "metadata": {},
   "source": [
    "![](img/07_melt.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9b1fa-eecf-4d59-a992-edbd16b4b21a",
   "metadata": {},
   "source": [
    "I want to collect all air quality $NO_2$ measurements in a single column (long format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29e98a-076d-4520-80d4-93f00b18db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2 = no2_pivoted.melt(id_vars=\"date.utc\")\n",
    "no_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a1cd5-99fb-4fa8-97ed-a6d2036b3743",
   "metadata": {},
   "source": [
    "    The pandas.melt() method on a DataFrame converts the data table from wide format to long format. The column headers become the variable names in a newly created column.\n",
    "\n",
    "The solution is the short version on how to apply pandas.melt(). The method will melt all columns NOT mentioned in id_vars together into two columns: A column with the column header names and a column with the values itself. The latter column gets by default the name value.\n",
    "\n",
    "The pandas.melt() method can be defined in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fbf87-ad1f-456d-8b7c-b5b7e5d5e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2 = no2_pivoted.melt(\n",
    "    id_vars=\"date.utc\",\n",
    "    value_vars=[\"BETR801\", \"FR04014\", \"London Westminster\"],\n",
    "    value_name=\"NO_2\",\n",
    "    var_name=\"id_location\",\n",
    ")\n",
    "\n",
    "no_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3d6df-ce4a-482e-a5ba-09eb10d65eb0",
   "metadata": {},
   "source": [
    "The result in the same, but in more detail defined:\n",
    "\n",
    "- value_vars defines explicitly which columns to melt together\n",
    "- value_name provides a custom column name for the values column instead of the default column name value\n",
    "- var_name provides a custom column name for the column collecting the column header names. Otherwise it takes the index name or a default variable\n",
    "\n",
    "Hence, the arguments value_name and var_name are just user-defined names for the two generated columns. The columns to melt are defined by id_vars and value_vars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bbaf5d-536c-4917-8cb9-f623b43899e8",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "- Sorting by one or more columns is supported by sort_values\n",
    "- The pivot function is purely restructuring of the data, pivot_table supports aggregations\n",
    "- The reverse of pivot (long to wide format) is melt (wide to long format)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b78e94-a358-47ed-89b8-ea0f41be84d5",
   "metadata": {},
   "source": [
    "## How to combine data from multiple tables?\n",
    "\n",
    "Données pour cette section :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3159a-0ca7-4d0e-b165-c660f8cf614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2_long.csv > data/air_quality_no2_long.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefcc265-87a1-4866-9276-754705eca244",
   "metadata": {},
   "source": [
    "### Données Nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581d59d-ebfa-4661-aedd-42b89e6b8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_no2 = pd.read_csv(\"data/air_quality_no2_long.csv\", parse_dates=True)\n",
    "\n",
    "air_quality_no2 = air_quality_no2[[\"date.utc\", \"location\", \"parameter\", \"value\"]]\n",
    "\n",
    "air_quality_no2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9bd1c-d8a3-480f-9606-05bc1398df87",
   "metadata": {},
   "source": [
    "### Données particules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8136e57-a7d7-4f08-84fa-cac061580f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_pm25_long.csv > data/air_quality_pm25_long.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb3802-8916-48e5-84cc-d56595a7d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_pm25 = pd.read_csv(\"data/air_quality_pm25_long.csv\", parse_dates=True)\n",
    "\n",
    "\n",
    "air_quality_pm25 = air_quality_pm25[[\"date.utc\", \"location\", \"parameter\", \"value\"]]\n",
    "\n",
    "\n",
    "air_quality_pm25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07159e7b-1fc7-4bef-8932-b64929c9df04",
   "metadata": {},
   "source": [
    "### Concatenation d'objets `DataFrame`\n",
    "\n",
    "![](img/08_concat_row.svg)\n",
    "\n",
    "I want to combine the measurements of and , two tables with a similar structure, in a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ebb69-d069-4183-a506-67b79193ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.concat([air_quality_pm25, air_quality_no2], axis=0)\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d008a-e275-4120-9cc5-999229b5c411",
   "metadata": {},
   "source": [
    "\n",
    "The concat() function performs concatenation operations of multiple tables along one of the axis (row-wise or column-wise).\n",
    "\n",
    "By default concatenation is along axis 0, so the resulting table combines the rows of the input tables. Let’s check the shape of the original and the concatenated tables to verify the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b738e-9afa-4c17-9254-f8caa6c4c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the ``air_quality_pm25`` table: \", air_quality_pm25.shape)\n",
    "\n",
    "print(\"Shape of the ``air_quality_no2`` table: \", air_quality_no2.shape)\n",
    "\n",
    "print(\"Shape of the resulting ``air_quality`` table: \", air_quality.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c5541-16eb-49d8-9626-cf7875115f69",
   "metadata": {},
   "source": [
    "Hence, the resulting table has 3178 = 1110 + 2068 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301faf2e-2cbc-4fdb-bfc6-ab3261afcc09",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "\n",
    "The axis argument will return in a number of pandas methods that can be applied along an axis. A DataFrame has two corresponding axes: the first running vertically downwards across rows (axis 0), and the second running horizontally across columns (axis 1). Most operations like concatenation or summary statistics are by default across rows (axis 0), but can be applied across columns as well.\n",
    "\n",
    "</div>\n",
    "\n",
    "Sorting the table on the datetime information illustrates also the combination of both tables, with the parameter column defining the origin of the table (either no2 from table air_quality_no2 or pm25 from table air_quality_pm25):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c809a07-ca04-41b7-9bea-dc562d454b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = air_quality.sort_values(\"date.utc\")\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17b3ea-5bdc-4383-87bd-84075a0ed520",
   "metadata": {},
   "source": [
    "In this specific example, the parameter column provided by the data ensures that each of the original tables can be identified. This is not always the case. the concat function provides a convenient solution with the keys argument, adding an additional (hierarchical) row index. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd2858-8288-47d8-9ea5-76ddb7093c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_ = pd.concat([air_quality_pm25, air_quality_no2], keys=[\"PM25\", \"NO2\"])\n",
    "air_quality_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23cb31-bc08-48e1-9ac8-5b378a32d346",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "The existence of multiple row/column indices at the same time has not been mentioned within these tutorials. Hierarchical indexing or MultiIndex is an advanced and powerful pandas feature to analyze higher dimensional data.\n",
    "\n",
    "Multi-indexing is out of scope for this pandas introduction. For the moment, remember that the function reset_index can be used to convert any level of an index to a column, e.g. air_quality.reset_index(level=0)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181c9f6-3d5d-42f0-b5fd-3560e7860674",
   "metadata": {},
   "source": [
    "### Join tables using a common identifier\n",
    "\n",
    "![](img/08_merge_left.svg)\n",
    "\n",
    "Add the station coordinates, provided by the stations metadata table, to the corresponding rows in the measurements table.\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "The air quality measurement station coordinates are stored in a data file air_quality_stations.csv, downloaded using the py-openaq package.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee37e67-f718-4c21-99a9-f20b053816ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_stations.csv  > data/air_quality_stations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e1ae3-3ebe-4d27-8cbc-8fc866934e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_coord = pd.read_csv(\"data/air_quality_stations.csv\")\n",
    "\n",
    "stations_coord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793fde14-25c2-4bcb-b1b6-dda800738f0c",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "The stations used in this example (FR04014, BETR801 and London Westminster) are just three entries enlisted in the metadata table. We only want to add the coordinates of these three to the measurements table, each on the corresponding rows of the air_quality table.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed96b38-b1fe-424a-8c8a-7500e101f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56a4bc-48f4-47f3-ad65-191034a820ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.merge(air_quality, stations_coord, how=\"left\", on=\"location\")\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610be20-89ee-44f3-b349-2307a602f8cc",
   "metadata": {},
   "source": [
    "Using the merge() function, for each of the rows in the air_quality table, the corresponding coordinates are added from the air_quality_stations_coord table. Both tables have the column location in common which is used as a key to combine the information. By choosing the left join, only the locations available in the air_quality (left) table, i.e. FR04014, BETR801 and London Westminster, end up in the resulting table. The merge function supports multiple join options similar to database-style operations.\n",
    "\n",
    "Add the parameter full description and name, provided by the parameters metadata table, to the measurements table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e6de7-ffb1-4318-aa13-4e2ba2cbfe7b",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "The air quality parameters metadata are stored in a data file air_quality_parameters.csv, downloaded using the py-openaq package.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d979e45-9ef4-4082-8c64-e55b834c5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# téléchargement d'un fichier CSV\n",
    "!curl https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_parameters.csv  > data/air_quality_parameters.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8c448-8d87-4e37-a7b7-519d6387e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_parameters = pd.read_csv(\"data/air_quality_parameters.csv\")\n",
    "\n",
    "air_quality_parameters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0aeef-c86d-40cb-8f90-080b313a9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.merge(\n",
    "    air_quality, air_quality_parameters, how=\"left\", left_on=\"parameter\", right_on=\"id\"\n",
    ")\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ea34a-d669-48ff-a7c4-0b4f790e6760",
   "metadata": {},
   "source": [
    "Compared to the previous example, there is no common column name. However, the parameter column in the air_quality table and the id column in the air_quality_parameters_name both provide the measured variable in a common format. The left_on and right_on arguments are used here (instead of just on) to make the link between the two tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fcb3b-5d80-4927-a025-cf25f77a0a5e",
   "metadata": {},
   "source": [
    "<div class 'alert alert-info'>\n",
    "\n",
    "\n",
    "REMEMBER\n",
    "\n",
    "- Multiple tables can be concatenated both column-wise and row-wise using the concat function.\n",
    "\n",
    "- For database-like merging/joining of tables, use the merge function.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc9bcf-080c-41cd-8c9c-2f3d35be45e9",
   "metadata": {},
   "source": [
    "## How to handle time series data with ease?¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8df4ba-774a-46ac-8413-7179036e2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67409a-2ab3-48ea-91a8-41d398f67860",
   "metadata": {},
   "source": [
    "Data used for this tutorial: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0cfaf-43c4-4e67-8e0d-0ea4fb5abcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.read_csv(\"data/air_quality_no2_long.csv\")\n",
    "\n",
    "air_quality = air_quality.rename(columns={\"date.utc\": \"datetime\"})\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c15a4-b640-490f-965f-8f35f8b639ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5247d62-0bdd-4992-be44-da450ed43b4a",
   "metadata": {},
   "source": [
    "### Using pandas datetime properties\n",
    "\n",
    "I want to work with the dates in the column datetime as datetime objects instead of plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7800f-e50d-4cd3-9900-a82aba7d10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"] = pd.to_datetime(air_quality[\"datetime\"])\n",
    "\n",
    "air_quality[\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009de10b-b40f-42eb-8c36-aba49b50d0c3",
   "metadata": {},
   "source": [
    "Initially, the values in datetime are character strings and do not provide any datetime operations (e.g. extract the year, day of the week,…). By applying the to_datetime function, pandas interprets the strings and convert these to datetime (i.e. datetime64[ns, UTC]) objects. In pandas we call these datetime objects similar to datetime.datetime from the standard library as pandas.Timestamp.\n",
    "\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "\n",
    "As many data sets do contain datetime information in one of the columns, pandas input function like pandas.read_csv() and pandas.read_json() can do the transformation to dates when reading the data using the parse_dates parameter with a list of the columns to read as Timestamp:\n",
    "\n",
    "`pd.read_csv(\"../data/air_quality_no2_long.csv\", parse_dates=[\"datetime\"])`\n",
    "\n",
    "</div>\n",
    "\n",
    "Why are these pandas.Timestamp objects useful? Let’s illustrate the added value with some example cases.\n",
    "\n",
    "> What is the start and end date of the time series data set we are working with?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89525b61-694c-4076-b82b-05e94e8692f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"].min(), air_quality[\"datetime\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f018f5-036d-40f1-9768-ee3dfb05aba3",
   "metadata": {},
   "source": [
    "Using pandas.Timestamp for datetimes enables us to calculate with date information and make them comparable. Hence, we can use this to get the length of our time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da6030-83a3-4bbe-b005-40e4b3e751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"].max() - air_quality[\"datetime\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380d289-926b-448f-9fcf-8bce884fc261",
   "metadata": {},
   "source": [
    "The result is a pandas.Timedelta object, similar to datetime.timedelta from the standard Python library and defining a time duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e212858-bfc9-4038-a626-ad1fa26b90c9",
   "metadata": {},
   "source": [
    "I want to add a new column to the DataFrame containing only the month of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f65fe-7c8b-44e3-973d-b556b28a4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"month\"] = air_quality[\"datetime\"].dt.month\n",
    "\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2d214-58f6-46e3-827b-e72204a00fbe",
   "metadata": {},
   "source": [
    "By using Timestamp objects for dates, a lot of time-related properties are provided by pandas. For example the month, but also year, weekofyear, quarter,… All of these properties are accessible by the dt accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500213e0-5de6-479b-ab5b-342c4cb81b9a",
   "metadata": {},
   "source": [
    "What is the average concentration for each day of the week for each of the measurement locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5c749-f806-46ae-a448-517ccc3feb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.groupby([air_quality[\"datetime\"].dt.weekday, \"location\"])[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca704a90-da47-4bee-8143-9fc211329834",
   "metadata": {},
   "source": [
    "Remember the split-apply-combine pattern provided by groupby from the tutorial on statistics calculation? Here, we want to calculate a given statistic (e.g. mean ) for each weekday and for each measurement location. To group on weekdays, we use the datetime property weekday (with Monday=0 and Sunday=6) of pandas Timestamp, which is also accessible by the dt accessor. The grouping on both locations and weekdays can be done to split the calculation of the mean on each of these combinations.\n",
    "\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "    \n",
    "    \n",
    "As we are working with a very short time series in these examples, the analysis does not provide a long-term representative result!\n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n",
    "Plot the typical $NO_2$ pattern during the day of our time series of all stations together. In other words, what is the average value for each hour of the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b3359-5519-488a-ac0f-2b8a5adcc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "air_quality.groupby(air_quality[\"datetime\"].dt.hour)[\"value\"].mean().plot(\n",
    "    kind=\"bar\", rot=0, ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Hour of the day\")\n",
    "# custom x label using matplotlib\n",
    "\n",
    "ax.set_ylabel(\"$NO_2 (µg/m^3)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49166d-5013-4693-a76a-6c298f32da33",
   "metadata": {},
   "source": [
    "Similar to the previous case, we want to calculate a given statistic (e.g. mean $NO_2$ ) for each hour of the day and we can use the split-apply-combine approach again. For this case, we use the datetime property hour of pandas Timestamp, which is also accessible by the dt accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417aaa6c-f8f3-43cf-95e5-a08250dd7b9f",
   "metadata": {},
   "source": [
    "## Datetime comme index\n",
    "\n",
    "In the tutorial on reshaping, pivot() was introduced to reshape the data table with each of the measurements locations as a separate column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56616f2-f1bc-41d3-a931-7243ba3316e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2 = air_quality.pivot(index=\"datetime\", columns=\"location\", values=\"value\")\n",
    "\n",
    "no_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e299afb8-c413-4c74-84da-946465207d44",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "By pivoting the data, the datetime information became the index of the table. In general, setting a column as an index can be achieved by the set_index function.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Working with a datetime index (i.e. DatetimeIndex) provides powerful functionalities. For example, we do not need the dt accessor to get the time series properties, but have these properties available on the index directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56279a2c-76b8-427e-b5c3-5b41854bf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2.index.year, no_2.index.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a854a-08cc-4c33-b70e-2a8debd9d358",
   "metadata": {},
   "source": [
    "Some other advantages are the convenient subsetting of time period or the adapted time scale on plots. Let’s apply this on our data.\n",
    "\n",
    "? Create a plot of the $NO_2$ values in the different stations from the 20th of May till the end of 21st of May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f9f18-e524-4500-8f3b-2def17ea8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2[\"2019-05-20\":\"2019-05-21\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307c3e0-caa0-4b0e-b4a0-acf2d9bab980",
   "metadata": {},
   "source": [
    "> By providing a string that parses to a datetime, a specific subset of the data can be selected on a DatetimeIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b543f3b-5ebb-4da7-9007-9da96c7ff332",
   "metadata": {},
   "source": [
    "### Resample a time series to another frequency\n",
    "\n",
    "? Aggregate the current hourly time series values to the monthly maximum value in each of the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20903a55-4351-4f49-9b64-69fb79d2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_max = no_2.resample(\"M\").max()\n",
    "\n",
    "monthly_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5dc097-8fb6-4ca6-86eb-a5e3b2eedbf5",
   "metadata": {},
   "source": [
    "> A very powerful method on time series data with a datetime index, is the ability to resample() time series to another frequency (e.g., converting secondly data into 5-minutely data).\n",
    "\n",
    "The `.resample()` method is similar to a groupby operation:\n",
    "\n",
    "- it provides a time-based grouping, by using a string (e.g. M, 5H,…) that defines the target frequency\n",
    "- it requires an aggregation function such as mean, max,…\n",
    "\n",
    "When defined, the frequency of the time series is provided by the freq attribute:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4e342-4493-46d9-9c98-9ee6b1c2875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_max.index.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13dd96-4562-4083-99a7-a16166e97815",
   "metadata": {},
   "source": [
    "? Make a plot of the daily mean value in each of the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8b207-3349-4324-9083-ca73f7d8e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2.resample(\"D\").mean().plot(style=\"-o\", figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5aad97-01b7-49d4-a118-764c27604cce",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "\n",
    "REMEMBER\n",
    "\n",
    "- Valid date strings can be converted to datetime objects using to_datetime function or as part of read functions.\n",
    "- Datetime objects in pandas support calculations, logical operations and convenient date-related properties using the dt accessor.\n",
    "- A DatetimeIndex contains these date-related properties and supports convenient slicing.\n",
    "- Resample is a powerful method to change the frequency of a time series.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e0f04-d9ef-461c-8129-3acb317248ec",
   "metadata": {},
   "source": [
    "## Comment manipuler des données textuelles ?\n",
    "\n",
    "Données utilisée dans cette section : Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be9cb0-5c49-40eb-ad09-70b41f4e5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762d3da-d06b-4c55-adc9-baa0fef1db98",
   "metadata": {},
   "source": [
    "? Make all name characters lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d37c8-2848-4fb3-aba3-82ed7cf457a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511f1fc-22b4-4653-94dc-4fb01a1422e9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> To make each of the strings in the Name column lowercase, select the Name column (see the tutorial on selection of data), add the str accessor and apply the lower method. As such, each of the strings is converted element-wise.\n",
    "\n",
    "Similar to datetime objects in the time series tutorial having a dt accessor, a number of specialized string methods are available when using the str accessor. These methods have in general matching names with the equivalent built-in string methods for single elements, but are applied element-wise (remember element-wise calculations?) on each of the values of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3322df-6fc3-456d-a546-c6cc0894b363",
   "metadata": {},
   "source": [
    "? Create a new column Surname that contains the surname of the passengers by extracting the part before the comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a3448-cfbe-45f9-b3cb-08ce552b3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c3b3e-652f-4ec0-93b4-82c8fae93f83",
   "metadata": {},
   "source": [
    "Using the Series.str.split() method, each of the values is returned as a list of 2 elements. The first element is the part before the comma and the second element is the part after the comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bec048-169f-49b6-ae05-aea0ee3e7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Surname\"] = titanic[\"Name\"].str.split(\",\").str.get(0)\n",
    "\n",
    "titanic[\"Surname\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6977f-979d-46d7-b88b-76c125253c83",
   "metadata": {},
   "source": [
    "As we are only interested in the first part representing the surname (element 0), we can again use the str accessor and apply Series.str.get() to extract the relevant part. Indeed, these string functions can be concatenated to combine multiple functions at once!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146fa274-736a-4911-9926-8f50e0f79349",
   "metadata": {},
   "source": [
    "? Extract the passenger data about the countesses on board of the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5518cf-d016-4847-b9fa-553a4878c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.contains(\"Countess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ed3a5-b88c-4db8-9c41-715b8214c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic[\"Name\"].str.contains(\"Countess\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854c148-fbaa-4025-a202-302448545ebd",
   "metadata": {},
   "source": [
    "> (Interested in her story? See [Wikipedia](https://fr.wikipedia.org/wiki/Lucy_No%C3%ABl_Leslie_Martha)!)\n",
    ">\n",
    "> The string method Series.str.contains() checks for each of the values in the column Name if the string contains the word Countess and returns for each of the values True (Countess is part of the name) or False (Countess is not part of the name). This output can be used to subselect the data using conditional (boolean) indexing introduced in the subsetting of data tutorial. As there was only one countess on the Titanic, we get one row as a result.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "More powerful extractions on strings are supported, as the Series.str.contains() and Series.str.extract() methods accept regular expressions, but out of scope of this tutorial.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7af4e-feef-4390-bc4d-d55aca22684d",
   "metadata": {},
   "source": [
    "? Which passenger of the Titanic has the longest name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d49ee-8333-4d89-91d6-4bb598b972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308708d3-135f-409b-8415-451659b55c97",
   "metadata": {},
   "source": [
    "To get the longest name we first have to get the lengths of each of the names in the Name column. By using pandas string methods, the Series.str.len() function is applied to each of the names individually (element-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdf62e-3865-4a52-8ce0-854389ef1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.len().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc558d-f360-4833-9654-514ee91d59ed",
   "metadata": {},
   "source": [
    "Next, we need to get the corresponding location, preferably the index label, in the table for which the name length is the largest. The idxmax() method does exactly that. It is not a string method and is applied to integers, so no str is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cecff-8b85-4a43-96da-d37de00ca2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Name\"].str.len().idxmax(), \"Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc541e3e-22a9-4dcb-b31e-d7e3e7e6e494",
   "metadata": {},
   "source": [
    "Based on the index name of the row (307) and the column (Name), we can do a selection using the loc operator, introduced in the tutorial on subsetting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5de507-e261-49ff-9e12-4e51725d3091",
   "metadata": {},
   "source": [
    "? In the “Sex” column, replace values of “male” by “M” and values of “female” by “F”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d6b31-8808-4ad7-b0bf-f4cab3bcee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Sex_short\"] = titanic[\"Sex\"].replace({\"male\": \"M\", \"female\": \"F\"})\n",
    "\n",
    "titanic[\"Sex_short\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10724850-539d-4e62-9c01-402cf4362871",
   "metadata": {},
   "source": [
    "Whereas replace() is not a string method, it provides a convenient way to use mappings or vocabularies to translate certain values. It requires a dictionary to define the mapping {from : to}.\n",
    "\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "    \n",
    "There is also a replace() method available to replace a specific set of characters. However, when having a mapping of multiple values, this would become:\n",
    "\n",
    "`titanic[\"Sex_short\"] = titanic[\"Sex\"].str.replace(\"female\", \"F\")`\n",
    "\n",
    "`titanic[\"Sex_short\"] = titanic[\"Sex_short\"].str.replace(\"male\", \"M\")`\n",
    "\n",
    "This would become cumbersome and easily lead to mistakes. Just think (or try out yourself) what would happen if those two statements are applied in the opposite order…\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a763fe0-5350-48d8-9168-1792dd011ec6",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "REMEMBER\n",
    "\n",
    "- String methods are available using the str accessor.\n",
    "-String methods work element-wise and can be used for conditional indexing.\n",
    "- The replace method is a convenient method to convert values according to a given dictionary.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e7025-38e5-4538-aed9-49b94f6c9471",
   "metadata": {},
   "source": [
    "## Ressources supplémentaires\n",
    "\n",
    "\n",
    "<div>\n",
    "<section id=\"community-tutorials\">\n",
    "<span id=\"communitytutorials\"></span><h1>Community tutorials<a class=\"headerlink\" href=\"#community-tutorials\" title=\"Permalink to this headline\">¶</a></h1>\n",
    "<p>This is a guide to many pandas tutorials by the community, geared mainly for new users.</p>\n",
    "<section id=\"pandas-cookbook-by-julia-evans\">\n",
    "<h2>pandas cookbook by Julia Evans<a class=\"headerlink\" href=\"#pandas-cookbook-by-julia-evans\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<p>The goal of this 2015 cookbook (by <a class=\"reference external\" href=\"https://jvns.ca\">Julia Evans</a>) is to\n",
    "give you some concrete examples for getting started with pandas. These\n",
    "are examples with real-world data, and all the bugs and weirdness that\n",
    "entails.\n",
    "For the table of contents, see the <a class=\"reference external\" href=\"https://github.com/jvns/pandas-cookbook\">pandas-cookbook GitHub\n",
    "repository</a>.</p>\n",
    "</section>\n",
    "<section id=\"pandas-workshop-by-stefanie-molin\">\n",
    "<h2>pandas workshop by Stefanie Molin<a class=\"headerlink\" href=\"#pandas-workshop-by-stefanie-molin\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<p>An introductory workshop by <a class=\"reference external\" href=\"https://github.com/stefmolin\">Stefanie Molin</a>\n",
    "designed to quickly get you up to speed with pandas using real-world datasets.\n",
    "It covers getting started with pandas, data wrangling, and data visualization\n",
    "(with some exposure to matplotlib and seaborn). The\n",
    "<a class=\"reference external\" href=\"https://github.com/stefmolin/pandas-workshop\">pandas-workshop GitHub repository</a>\n",
    "features detailed environment setup instructions (including a Binder environment),\n",
    "slides and notebooks for following along, and exercises to practice the concepts.\n",
    "There is also a lab with new exercises on a dataset not covered in the workshop for\n",
    "additional practice.</p>\n",
    "</section>\n",
    "<section id=\"learn-pandas-by-hernan-rojas\">\n",
    "<h2>Learn pandas by Hernan Rojas<a class=\"headerlink\" href=\"#learn-pandas-by-hernan-rojas\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<p>A set of lesson for new pandas users: <a class=\"reference external\" href=\"https://bitbucket.org/hrojas/learn-pandas\">https://bitbucket.org/hrojas/learn-pandas</a></p>\n",
    "</section>\n",
    "<section id=\"practical-data-analysis-with-python\">\n",
    "<h2>Practical data analysis with Python<a class=\"headerlink\" href=\"#practical-data-analysis-with-python\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<p>This <a class=\"reference external\" href=\"https://wavedatalab.github.io/datawithpython\">guide</a> is an introduction to the data analysis process using the Python data ecosystem and an interesting open dataset.\n",
    "There are four sections covering selected topics as <a class=\"reference external\" href=\"https://wavedatalab.github.io/datawithpython/munge.html\">munging data</a>,\n",
    "<a class=\"reference external\" href=\"https://wavedatalab.github.io/datawithpython/aggregate.html\">aggregating data</a>, <a class=\"reference external\" href=\"https://wavedatalab.github.io/datawithpython/visualize.html\">visualizing data</a>\n",
    "and <a class=\"reference external\" href=\"https://wavedatalab.github.io/datawithpython/timeseries.html\">time series</a>.</p>\n",
    "</section>\n",
    "<section id=\"exercises-for-new-users\">\n",
    "<span id=\"tutorial-exercises-new-users\"></span><h2>Exercises for new users<a class=\"headerlink\" href=\"#exercises-for-new-users\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<p>Practice your skills with real data sets and exercises.\n",
    "For more resources, please visit the main <a class=\"reference external\" href=\"https://github.com/guipsamora/pandas_exercises\">repository</a>.</p>\n",
    "</section>\n",
    "<section id=\"modern-pandas\">\n",
    "<span id=\"tutorial-modern\"></span><h2>Modern pandas<a class=\"headerlink\" href=\"#modern-pandas\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<p>Tutorial series written in 2016 by\n",
    "<a class=\"reference external\" href=\"https://github.com/TomAugspurger\">Tom Augspurger</a>.\n",
    "The source may be found in the GitHub repository\n",
    "<a class=\"reference external\" href=\"https://github.com/TomAugspurger/effective-pandas\">TomAugspurger/effective-pandas</a>.</p>\n",
    "<ul class=\"simple\">\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/modern-1-intro.html\">Modern Pandas</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/method-chaining.html\">Method Chaining</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/modern-3-indexes.html\">Indexes</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/modern-4-performance.html\">Performance</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/modern-5-tidy.html\">Tidy Data</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/modern-6-visualization.html\">Visualization</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tomaugspurger.github.io/modern-7-timeseries.html\">Timeseries</a></p></li>\n",
    "</ul>\n",
    "</section>\n",
    "<section id=\"excel-charts-with-pandas-vincent-and-xlsxwriter\">\n",
    "<h2>Excel charts with pandas, vincent and xlsxwriter<a class=\"headerlink\" href=\"#excel-charts-with-pandas-vincent-and-xlsxwriter\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<ul class=\"simple\">\n",
    "<li><p><a class=\"reference external\" href=\"https://pandas-xlsxwriter-charts.readthedocs.io/\">Using Pandas and XlsxWriter to create Excel charts</a></p></li>\n",
    "</ul>\n",
    "</section>\n",
    "<section id=\"video-tutorials\">\n",
    "<h2>Video tutorials<a class=\"headerlink\" href=\"#video-tutorials\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<ul class=\"simple\">\n",
    "<li><p><a class=\"reference external\" href=\"https://www.youtube.com/watch?v=5JnMutdy6Fw\">Pandas From The Ground Up</a>\n",
    "(2015) (2:24)\n",
    "<a class=\"reference external\" href=\"https://github.com/brandon-rhodes/pycon-pandas-tutorial\">GitHub repo</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://www.youtube.com/watch?v=-NR-ynQg0YM\">Introduction Into Pandas</a>\n",
    "(2016) (1:28)\n",
    "<a class=\"reference external\" href=\"https://github.com/chendaniely/2016-pydata-carolinas-pandas\">GitHub repo</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://www.youtube.com/watch?v=7vuO9QXDN50\">Pandas: .head() to .tail()</a>\n",
    "(2016) (1:26)\n",
    "<a class=\"reference external\" href=\"https://github.com/TomAugspurger/pydata-chi-h2t\">GitHub repo</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://www.youtube.com/playlist?list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y\">Data analysis in Python with pandas</a>\n",
    "(2016-2018)\n",
    "<a class=\"reference external\" href=\"https://github.com/justmarkham/pandas-videos\">GitHub repo</a> and\n",
    "<a class=\"reference external\" href=\"https://nbviewer.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb\">Jupyter Notebook</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://www.youtube.com/playlist?list=PL5-da3qGB5IBITZj_dYSFqnd_15JgqwA6\">Best practices with pandas</a>\n",
    "(2018)\n",
    "<a class=\"reference external\" href=\"https://github.com/justmarkham/pycon-2018-tutorial\">GitHub repo</a> and\n",
    "<a class=\"reference external\" href=\"https://nbviewer.org/github/justmarkham/pycon-2018-tutorial/blob/master/tutorial.ipynb\">Jupyter Notebook</a></p></li>\n",
    "</ul>\n",
    "</section>\n",
    "<section id=\"various-tutorials\">\n",
    "<h2>Various tutorials<a class=\"headerlink\" href=\"#various-tutorials\" title=\"Permalink to this headline\">¶</a></h2>\n",
    "<ul class=\"simple\">\n",
    "<li><p><a class=\"reference external\" href=\"https://wesmckinney.com/archives.html\">Wes McKinney’s (pandas BDFL) blog</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"http://www.randalolson.com/2012/08/06/statistical-analysis-made-easy-in-python/\">Statistical analysis made easy in Python with SciPy and pandas DataFrames, by Randal Olson</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://conference.scipy.org/scipy2013/tutorial_detail.php?id=109\">Statistical Data Analysis in Python, tutorial videos, by Christopher Fonnesbeck from SciPy 2013</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://nbviewer.ipython.org/github/twiecki/financial-analysis-python-tutorial/blob/master/1.%20Pandas%20Basics.ipynb\">Financial analysis in Python, by Thomas Wiecki</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/\">Intro to pandas data structures, by Greg Reda</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/\">Pandas and Python: Top 10, by Manish Amde</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\">Pandas DataFrames Tutorial, by Karlijn Willems</a></p></li>\n",
    "<li><p><a class=\"reference external\" href=\"https://tutswiki.com/pandas-cookbook/chapter1/\">A concise tutorial with real life examples</a></p></li>\n",
    "</ul>\n",
    "</section>\n",
    "</section>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "830c0d9e-857c-4be2-8f82-bc996d57f321",
   "metadata": {},
   "source": [
    "# delete folders before saving and commiting\n",
    "!rm -r data/\n",
    "!rm -r export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a6148-d722-4e64-af51-96b3ed7a516c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
